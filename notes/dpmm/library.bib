
@article{besley_estimating_2012,
	title = {Estimating the Peace Dividend: The Impact of Violence on House Prices in Northern Ireland},
	volume = {102},
	issn = {0002-8282},
	pages = {810--833},
	number = {2},
	journaltitle = {The American Economic Review},
	shortjournal = {{AER}},
	author = {Besley, Timothy and Mueller, Hannes},
	date = {2012-04},
	langid = {english},
	file = {Besley and Mueller - 2012 - Estimating the Peace Dividend The Impact of Viole.pdf:/home/cloud/Dropbox/zotero/Besley and Mueller - 2012 - Estimating the Peace Dividend The Impact of Viole.pdf:application/pdf},
}

@book{hastie_elements_2009,
	location = {New York, {NY}},
	edition = {2nd ed},
	title = {The elements of statistical learning: data mining, inference, and prediction},
	isbn = {978-0-387-84857-0 978-0-387-84858-7},
	series = {Springer series in statistics},
	shorttitle = {The elements of statistical learning},
	pagetotal = {745},
	publisher = {Springer},
	author = {Hastie, Trevor and Tibshirani, Robert and Friedman, J. H.},
	date = {2009},
	keywords = {Machine learning, Bioinformatics, Computational intelligence, Data mining, Forecasting, Inference, Methodology, Statistics},
	file = {ESLII.pdf:/home/cloud/Dropbox/zotero/ESLII.pdf:application/pdf},
}

@book{bishop_pattern_2006,
	location = {New York},
	title = {Pattern recognition and machine learning},
	isbn = {978-0-387-31073-2},
	series = {Information science and statistics},
	pagetotal = {738},
	publisher = {Springer},
	author = {Bishop, Christopher M.},
	date = {2006},
	langid = {english},
	keywords = {Machine learning, Pattern perception},
	file = {Bishop-Pattern-Recognition-and-Machine-Learning-2006.pdf:/home/cloud/Dropbox/zotero/Bishop-Pattern-Recognition-and-Machine-Learning-2006.pdf:application/pdf},
}

@article{baum_maximization_1970,
	title = {A Maximization Technique Occurring in the Statistical Analysis of Probabilistic Functions of Markov Chains},
	volume = {41},
	issn = {0003-4851},
	url = {https://www.jstor.org/stable/2239727},
	pages = {164--171},
	number = {1},
	journaltitle = {The Annals of Mathematical Statistics},
	author = {Baum, Leonard E. and Petrie, Ted and Soules, George and Weiss, Norman},
	urldate = {2024-08-02},
	date = {1970},
	note = {Publisher: Institute of Mathematical Statistics},
	file = {Baum et al_1970_A Maximization Technique Occurring in the Statistical Analysis of Probabilistic.pdf:/home/cloud/Dropbox/zotero/Baum et al_1970_A Maximization Technique Occurring in the Statistical Analysis of Probabilistic.pdf:application/pdf},
}

@article{james_d_hamilton_quasi-bayesian_1991,
	title = {A Quasi-Bayesian Approach to Estimating Parameters for Mixtures of Normal Distributions},
	volume = {9},
	pages = {27--39},
	number = {1},
	journaltitle = {Journal of Business \& Economic Statistics},
	author = {{James D. Hamilton}},
	date = {1991-01},
	langid = {english},
	file = {2024 - A Quasi-Bayesian Approach to Estimating Parameters.pdf:/home/cloud/Zotero/storage/32JDUGTX/2024 - A Quasi-Bayesian Approach to Estimating Parameters.pdf:application/pdf},
}

@book{murphy_machine_2013,
	location = {Cambridge, Mass.},
	edition = {4. print. (fixed many typos)},
	title = {Machine learning: a probabilistic perspective},
	isbn = {978-0-262-01802-9},
	series = {Adaptive computation and machine learning series},
	shorttitle = {Machine learning},
	pagetotal = {1071},
	publisher = {{MIT} Press},
	author = {Murphy, Kevin P.},
	date = {2013},
	langid = {english},
	file = {PDF:/home/cloud/Zotero/storage/I2TESQ2X/Murphy - 2013 - Machine learning a probabilistic perspective.pdf:application/pdf},
}

@article{neal_markov_2000,
	title = {Markov Chain Sampling Methods for Dirichlet Process Mixture Models},
	volume = {9},
	pages = {249--265},
	number = {2},
	journaltitle = {Journal of Computational and Graphical Statistics},
	author = {Neal, Radford M},
	date = {2000},
	langid = {english},
	file = {Neal2000a:/home/cloud/Dropbox/zotero/Neal2000a.pdf:application/pdf},
}

@article{blei_variational_2006,
	title = {Variational inference for Dirichlet process mixtures},
	volume = {1},
	issn = {1936-0975},
	url = {https://projecteuclid.org/journals/bayesian-analysis/volume-1/issue-1/Variational-inference-for-Dirichlet-process-mixtures/10.1214/06-BA104.full},
	doi = {10.1214/06-BA104},
	abstract = {Dirichlet process ({DP}) mixture models are the cornerstone of nonparametric Bayesian statistics, and the development of Monte-Carlo Markov chain ({MCMC}) sampling methods for {DP} mixtures has enabled the application of nonparametric Bayesian methods to a variety of practical data analysis problems. However, {MCMC} sampling can be prohibitively slow, and it is important to explore alternatives. One class of alternatives is provided by variational methods, a class of deterministic algorithms that convert inference problems into optimization problems (Opper and Saad 2001; Wainwright and Jordan 2003). Thus far, variational methods have mainly been explored in the parametric setting, in particular within the formalism of the exponential family (Attias 2000; Ghahramani and Beal 2001; Blei et al. 2003). In this paper, we present a variational inference algorithm for {DP} mixtures. We present experiments that compare the algorithm to Gibbs sampling algorithms for {DP} mixtures of Gaussians and present an application to a large-scale image analysis problem.},
	number = {1},
	journaltitle = {Bayesian Analysis},
	shortjournal = {Bayesian Anal.},
	author = {Blei, David M. and Jordan, Michael I.},
	urldate = {2025-02-14},
	date = {2006-03-01},
	langid = {english},
	file = {06-BA104-1:/home/cloud/Dropbox/zotero/06-BA104-1.pdf:application/pdf},
}

@article{raykov_simple_2016,
	title = {Simple approximate {MAP} inference for Dirichlet processes mixtures},
	volume = {10},
	issn = {1935-7524},
	url = {https://projecteuclid.org/journals/electronic-journal-of-statistics/volume-10/issue-2/Simple-approximate-MAP-inference-for-Dirichlet-processes-mixtures/10.1214/16-EJS1196.full},
	doi = {10.1214/16-EJS1196},
	abstract = {The Dirichlet process mixture model ({DPMM}) is a ubiquitous, ﬂexible Bayesian nonparametric statistical model. However, full probabilistic inference in this model is analytically intractable, so that computationally intensive techniques such as Gibbs sampling are required. As a result, {DPMM}-based methods, which have considerable potential, are restricted to applications in which computational resources and time for inference is plentiful. For example, they would not be practical for digital signal processing on embedded hardware, where computational resources are at a serious premium. Here, we develop a simpliﬁed yet statistically rigorous approximate maximum a-posteriori ({MAP}) inference algorithm for {DPMMs}. This algorithm is as simple as {DP}-means clustering, solves the {MAP} problem as well as Gibbs sampling, while requiring only a fraction of the computational eﬀort.† Unlike related small variance asymptotics ({SVA}), our method is non-degenerate and so inherits the “rich get richer” property of the Dirichlet process. It also retains a non-degenerate closedform likelihood which enables out-of-sample calculations and the use of standard tools such as cross-validation. We illustrate the beneﬁts of our algorithm on a range of examples and contrast it to variational, {SVA} and sampling approaches from both a computational complexity perspective as well as in terms of clustering performance. We demonstrate the wide applicabiity of our approach by presenting an approximate {MAP} inference method for the inﬁnite hidden Markov model whose performance contrasts favorably with a recently proposed hybrid {SVA} approach. Similarly, we show how our algorithm can applied to a semiparametric mixed-eﬀects regression model where the random eﬀects distribution is modelled using an inﬁnite mixture model, as used in longitudinal progression modelling in population health science. Finally, we propose directions for future research on approximate {MAP} inference in Bayesian nonparametrics.},
	number = {2},
	journaltitle = {Electronic Journal of Statistics},
	shortjournal = {Electron. J. Statist.},
	author = {Raykov, Yordan P. and Boukouvalas, Alexis and Little, Max A.},
	urldate = {2025-02-14},
	date = {2016-01-01},
	langid = {english},
	file = {16-EJS1196-1:/home/cloud/Dropbox/zotero/16-EJS1196-1.pdf:application/pdf},
}

@article{raftery_practical_1992,
	title = {[Practical Markov Chain Monte Carlo]: Comment: One Long Run with Diagnostics: Implementation Strategies for Markov Chain Monte Carlo},
	volume = {7},
	issn = {0883-4237},
	url = {https://projecteuclid.org/journals/statistical-science/volume-7/issue-4/Practical-Markov-Chain-Monte-Carlo--Comment--One-Long/10.1214/ss/1177011143.full},
	doi = {10.1214/ss/1177011143},
	shorttitle = {[Practical Markov Chain Monte Carlo]},
	number = {4},
	journaltitle = {Statistical Science},
	shortjournal = {Statist. Sci.},
	author = {Raftery, Adrian E. and Lewis, Steven M.},
	urldate = {2025-02-24},
	date = {1992-11-01},
	file = {PDF:/home/cloud/Zotero/storage/F998NJCD/Raftery and Lewis - 1992 - [Practical Markov Chain Monte Carlo] Comment One Long Run with Diagnostics Implementation Strateg.pdf:application/pdf},
}

@article{blackwell_ferguson_1973,
	title = {Ferguson Distributions Via Polya Urn Schemes},
	volume = {1},
	issn = {0090-5364},
	url = {https://projecteuclid.org/journals/annals-of-statistics/volume-1/issue-2/Ferguson-Distributions-Via-Polya-Urn-Schemes/10.1214/aos/1176342372.full},
	doi = {10.1214/aos/1176342372},
	number = {2},
	journaltitle = {The Annals of Statistics},
	shortjournal = {Ann. Statist.},
	author = {Blackwell, David and {MacQueen}, James B.},
	urldate = {2025-02-25},
	date = {1973-03-01},
	file = {PDF:/home/cloud/Zotero/storage/6ELJS6YH/Blackwell and MacQueen - 1973 - Ferguson Distributions Via Polya Urn Schemes.pdf:application/pdf},
}
