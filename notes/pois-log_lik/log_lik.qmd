---
title: "Aggregating Log-Likelihoods"
date: "2023-12-30"
---

This will be a trivial point, but if feasible it can be more computationally efficient to work with an aggregated version of the log likelihood.

Let $y_1, y_2, \ldots, y_N$ be a collection of *i.i.d.* observations with a log-likelihood function

$$
\ell(\theta | y) = \sum_{i=1}^N \log f(y_i | \theta)
$$

for some arbitrary probability function $f(\cdot)$. Obviously, we can group identical observations together where $y_i = y_j$ for $i \neq j$. Then,

$$
\ell(\theta | y) = \sum_{j=1}^K N_j \log f(y_j | \theta)
$$

where $N_j$ denotes the number of times $y_j$ appears in the dataset for $K$ unique values.

In the case where $y_i \sim \text{Poisson}\left(\lambda \right)$, this can easily coded in Stan as follows:

```{stan output.var = "x"}
#| echo: true
#| eval: false
#| cache: false
#| file: "poisson_aggregated.stan"
```

## Benchmarking

For a simulated dataset of 2,000 observations drawn from a poisson distribution with $\lambda = 25$, there is a decrease in runtime when using the aggregated version of the model.

```{R class.source = 'fold-hide', message = F, dev = "png", dev.args = list(bg="transparent")}
library(cmdstanr)
library(dplyr)
library(ggplot2)
library(ggthemes)
library(parallel)

options(mc.cores = parallel::detectCores() - 1)

mod1 <- cmdstan_model("./poisson.stan")
mod2 <- cmdstan_model("./poisson_aggregated.stan")

bench <- function(expr) {
    start <- Sys.time()
    expr
    end <- Sys.time()
    end - start
}

stan_sample <- function(mod, data) {
    mod$sample(data = data, chains = 1, show_messages = F, show_exceptions = F)
}

###
# Simulate data
N <- 2e3
lambda <- 25
y <- rpois(N, lambda)

# Model 1 data
data <- list(N = N, y = y)

# Model 2 data - aggregated
df <- data.frame(y = y) |> group_by(y) |> summarise(n = n())
agg_data <- list(K = nrow(df), n_obs = df$n, y = df$y)

###
# Run each model for `iter` iterations
iter <- 100

# I believe `mclapply` uses a process pool, so discard the first
# mc.cores iterations which will have an associated startup cost.
burnin <- 10

l1 <- mclapply(1:iter, \(i) bench(stan_sample(mod1, data)))
l2 <- mclapply(1:iter, \(i) bench(stan_sample(mod2, agg_data)))

est <- data.frame(time = c(unlist(l1[burnin+1:iter]),
                           unlist(l2[burnin+1:iter])),
                  model = c(rep("Unaggregated", iter - burnin),
                            rep("Aggregated", iter - burnin)))

ggplot(est, aes(x = model, y = time, color = model)) +
    geom_jitter(width = 0.1, alpha = 0.5) +
    xlab("Model") +
    ylab("Runtime (sec)") +
    theme_minimal(base_size = 12) +
    theme(axis.title.x = element_text(face = "bold"),
          axis.title.y = element_text(face = "bold"),
          legend.position = "none") +
    scale_colour_solarized()
```

### Miscellaneous

Stan code for the unaggregated model.

```{stan output.var = "x"}
#| eval: false
#| echo: true
#| cache: false
#| file: "poisson.stan"
```

Computing environment:

```{R}
sessionInfo()
sprintf("cmdstan version: %s", cmdstan_version()) |> print()
```
